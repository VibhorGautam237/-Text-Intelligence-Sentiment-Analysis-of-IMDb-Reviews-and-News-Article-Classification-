{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24fb9268-4081-43d1-9cfd-deea7d547d57",
   "metadata": {},
   "source": [
    "#  Part B: News Article Classification:\n",
    "# OVERVIEW\n",
    "The \"overview\" section describes a project aimed at developing a machine learning model to classify news articles into predefined categories, such as sports, politics, and technology, based on their content. the purpose of this automation is to improve content management and recommendation systems for news organizations, social media platforms, and aggregators, ultimately making it eaiser for readers to access relevant information based on their inteersts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f382b7-9a9c-4dc9-9d87-39478d35f412",
   "metadata": {},
   "source": [
    "# PROBLEM STATEMENT \n",
    "The problem statement describes the goal of building a classification model for news articles and outlines the steps involved in developing this solution\n",
    "this primary objective is to build a classification model that can automatically categorize large volumes of news articles into predefined categrories."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5745592-bd17-4f2b-bebf-c990155aaef4",
   "metadata": {},
   "source": [
    "# Information about structure of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be2f66d3-c3db-4013-b38b-777fa0f8aa76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from datetime import datetime\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15141ec1-925a-4b2b-a0b0-9c47f48205e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:\\\\Users\\\\india\\\\Downloads\\\\data_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6208decb-b17e-47c5-b3bd-30e73ffe6e87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 5)\n",
      "category             object\n",
      "headline             object\n",
      "links                object\n",
      "short_description    object\n",
      "keywords             object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>links</th>\n",
       "      <th>short_description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>143 Miles in 35 Days: Lessons Learned</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/running-l...</td>\n",
       "      <td>Resting is part of training. I've confirmed wh...</td>\n",
       "      <td>running-lessons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Talking to Yourself: Crazy or Crazy Helpful?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/talking-t...</td>\n",
       "      <td>Think of talking to yourself as a tool to coac...</td>\n",
       "      <td>talking-to-yourself-crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Crenezumab: Trial Will Gauge Whether Alzheimer...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/crenezuma...</td>\n",
       "      <td>The clock is ticking for the United States to ...</td>\n",
       "      <td>crenezumab-alzheimers-disease-drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Oh, What a Difference She Made</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/meaningfu...</td>\n",
       "      <td>If you want to be busy, keep trying to be perf...</td>\n",
       "      <td>meaningful-life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Green Superfoods</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/green-sup...</td>\n",
       "      <td>First, the bad news: Soda bread, corned beef a...</td>\n",
       "      <td>green-superfoods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           headline  \\\n",
       "0  WELLNESS              143 Miles in 35 Days: Lessons Learned   \n",
       "1  WELLNESS       Talking to Yourself: Crazy or Crazy Helpful?   \n",
       "2  WELLNESS  Crenezumab: Trial Will Gauge Whether Alzheimer...   \n",
       "3  WELLNESS                     Oh, What a Difference She Made   \n",
       "4  WELLNESS                                   Green Superfoods   \n",
       "\n",
       "                                               links  \\\n",
       "0  https://www.huffingtonpost.com/entry/running-l...   \n",
       "1  https://www.huffingtonpost.com/entry/talking-t...   \n",
       "2  https://www.huffingtonpost.com/entry/crenezuma...   \n",
       "3  https://www.huffingtonpost.com/entry/meaningfu...   \n",
       "4  https://www.huffingtonpost.com/entry/green-sup...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Resting is part of training. I've confirmed wh...   \n",
       "1  Think of talking to yourself as a tool to coac...   \n",
       "2  The clock is ticking for the United States to ...   \n",
       "3  If you want to be busy, keep trying to be perf...   \n",
       "4  First, the bad news: Soda bread, corned beef a...   \n",
       "\n",
       "                             keywords  \n",
       "0                     running-lessons  \n",
       "1           talking-to-yourself-crazy  \n",
       "2  crenezumab-alzheimers-disease-drug  \n",
       "3                     meaningful-life  \n",
       "4                    green-superfoods  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709320ec-eb68-49d3-8fbe-16e54d3947bb",
   "metadata": {},
   "source": [
    "#  1. Data Collection and Preprocessing :\n",
    "# ● Collect a dataset of labeled news articles (sports, politics, technology etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f33958a-8bbb-457c-8db7-1fc15f091b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Data:\n",
      "       category                                           headline  \\\n",
      "0      WELLNESS              143 Miles in 35 Days: Lessons Learned   \n",
      "1      WELLNESS       Talking to Yourself: Crazy or Crazy Helpful?   \n",
      "2      WELLNESS  Crenezumab: Trial Will Gauge Whether Alzheimer...   \n",
      "3      WELLNESS                     Oh, What a Difference She Made   \n",
      "4      WELLNESS                                   Green Superfoods   \n",
      "...         ...                                                ...   \n",
      "49995    SPORTS  This Baseball Team Learned There's A Wrong Way...   \n",
      "49996    SPORTS  Some Young Spurs Fan Dabbed 38 Times In A Sing...   \n",
      "49997    SPORTS  Rasheed Wallace Ejected From Knicks-Suns Game ...   \n",
      "49998    SPORTS  Why Jake Plummer And Other NFL Players Are Pus...   \n",
      "49999    SPORTS  Simone Biles Isn't The Next Anyone, She's 'The...   \n",
      "\n",
      "                                                   links  \\\n",
      "0      https://www.huffingtonpost.com/entry/running-l...   \n",
      "1      https://www.huffingtonpost.com/entry/talking-t...   \n",
      "2      https://www.huffingtonpost.com/entry/crenezuma...   \n",
      "3      https://www.huffingtonpost.com/entry/meaningfu...   \n",
      "4      https://www.huffingtonpost.com/entry/green-sup...   \n",
      "...                                                  ...   \n",
      "49995  https://www.huffingtonpost.com/entry/san-jose-...   \n",
      "49996  https://www.huffingtonpost.com/entry/dab-kid-s...   \n",
      "49997  https://www.huffingtonpost.com/entry/rasheed-w...   \n",
      "49998  https://www.huffingtonpost.comhttp://extras.de...   \n",
      "49999  https://www.huffingtonpost.com/entry/the-first...   \n",
      "\n",
      "                                       short_description  \\\n",
      "0      Resting is part of training. I've confirmed wh...   \n",
      "1      Think of talking to yourself as a tool to coac...   \n",
      "2      The clock is ticking for the United States to ...   \n",
      "3      If you want to be busy, keep trying to be perf...   \n",
      "4      First, the bad news: Soda bread, corned beef a...   \n",
      "...                                                  ...   \n",
      "49995  Many fans were pissed after seeing the minor l...   \n",
      "49996             Never change, young man. Never change.   \n",
      "49997  Wallace was hit with a first technical for a h...   \n",
      "49998  They believe CBD could be an alternative to po...   \n",
      "49999             The gymnast is in a league of her own.   \n",
      "\n",
      "                                                keywords  \n",
      "0                                        running-lessons  \n",
      "1                              talking-to-yourself-crazy  \n",
      "2                     crenezumab-alzheimers-disease-drug  \n",
      "3                                        meaningful-life  \n",
      "4                                       green-superfoods  \n",
      "...                                                  ...  \n",
      "49995            san-jose-giants-japanese-heritage-night  \n",
      "49996                          dab-kid-san-antonio-spurs  \n",
      "49997  rasheed-wallace-ejected-knicks-suns-ball-dont-lie  \n",
      "49998                                                NaN  \n",
      "49999                             the-first-simone-biles  \n",
      "\n",
      "[50000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "    import pandas as pd\n",
    "\n",
    "    # Simulate a small dataset of labeled news articles\n",
    "    data = {\n",
    "        'article_text' ,\n",
    "      \n",
    "        'label', \n",
    "            \"sports\",\n",
    "            \"politics\",\n",
    "            \"technology\",\n",
    "    }\n",
    "    df = df = pd.read_csv(\"C:\\\\Users\\\\india\\\\Downloads\\\\data_news.csv\")\n",
    "    print(\"Collected Data:\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07b0ed4-e615-4050-8df6-07ff40e7d97d",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "              + This part demonstrates how to \"collect\" a dataset. For simplicity, fetch_20newsgroups is used, which is a common dataset for text classification. In a real-world project, you would replace this with loading your actual dataset from a file (e.g.,pd.read_csv('news_articles.csv.csv') or pd.read_json('news_articles.json')). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1abb547-27b5-4ec9-8c4c-6b9980a914ac",
   "metadata": {},
   "source": [
    "#  ● Cleanand preprocess the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632426fa-2c1e-4b60-9f8c-dcd13d621440",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import re\n",
    "    import nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "    nltk.download('stopwords', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def preprocess_text(text):\n",
    "        text = text.lower() # Convert to lowercase\n",
    "        text = re.sub(r'\\S*@\\S*\\s?', '', text) # Remove emails\n",
    "        text = re.sub(r'http\\S+', '', text) # Remove URLs\n",
    "        text = re.sub(r'[^a-z\\s]', '', text) # Remove non-alphabetic characters\n",
    "        words = text.split()\n",
    "        words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words] # Remove stopwords and lemmatize\n",
    "        return ' '.join(words)\n",
    "\n",
    "    df['cleaned_text'] = df['text'].apply(preprocess_text)\n",
    "    print(\"\\nText data cleaned and preprocessed.\")\n",
    "    print(f\"Sample cleaned article:\\n{df['cleaned_text'][0][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b8797f-bf77-47ed-8fa2-b034221a3f62",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "            + This section defines a preprocess_text function that performs common text cleaning steps: converting to lowercase, removing emails and URLs, removing non-alphabetic characters, removing stopwords, and lemmatizing words. The apply method is then used to apply this function to the 'text' column, creating a new 'cleaned_text' column. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa539580-c875-49eb-ac1c-dd7c4fc28040",
   "metadata": {},
   "source": [
    "# ● Handle missing data, if any, and ensure the text is ready for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e01bf5-8e1e-43dd-894d-2ccc486efc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Check for missing values\n",
    "    print(f\"\\nMissing values before handling:\\n{df.isnull().sum()}\")\n",
    "\n",
    "    # Handle missing values (e.g., fill with empty string or drop rows)\n",
    "    df.dropna(subset=['cleaned_text'], inplace=True) # Drop rows where cleaned_text might be NaN\n",
    "    df['cleaned_text'].fillna('', inplace=True) # Fill any remaining NaN with empty string\n",
    "\n",
    "    print(f\"\\nMissing values after handling:\\n{df.isnull().sum()}\")\n",
    "    print(\"\\nText is now ready for feature extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17beb3-4f7f-4e9d-b4fa-9bd6f910a4e2",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "            + This part explicitly checks for missing values in the DataFrame. While the preprocessing steps might not directly create NaN values in the 'cleaned_text' column if the original 'text' column is clean, it's good practice to include dropna or fillna to ensure data integrity and readiness for subsequent steps like feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9599d1e6-5715-4e15-918a-ab780aece3bf",
   "metadata": {},
   "source": [
    "#  2. Feature Extraction\n",
    "# ● Usemethods like TF-IDF, word embeddings (e.g., Word2Vec, GloVe), or bag-of-words to convert text data into numerical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a6791-4186-4c7f-bd56-6caa96e1f80e",
   "metadata": {},
   "source": [
    "# 1. Bag-of-Words (BoW):\n",
    "      This method represents text as a bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a511645-f114-48b8-a585-88e2db2d6d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words features:\n",
      " [[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]]\n",
      "Feature names (words): ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
     ]
    }
   ],
   "source": [
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    corpus = ['This is the first document.', 'This document is the second document.', 'And this is the third one.']\n",
    "    vectorizer = CountVectorizer()\n",
    "    X_bow = vectorizer.fit_transform(corpus)\n",
    "    print(\"Bag-of-Words features:\\n\", X_bow.toarray())\n",
    "    print(\"Feature names (words):\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c885dea9-a7e8-405c-bbe8-1173c8074687",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "    CountVectorizer converts a collection of text documents to a matrix of token counts. Each row represents a document, and each column represents a unique word from the corpus, with the value being the count of that word in the document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d618570-37a1-4a60-8291-f326cd417347",
   "metadata": {},
   "source": [
    "# 2. TF-IDF (Term Frequency-Inverse Document Frequency):\n",
    "      This method reflects how important a word is to a document in a corpus. It increases proportionally to the number of times a word appears in the document but is offset by the frequency of the word in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26261700-ad5a-47a6-a065-a577de49f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF features:\n",
      " [[0.         0.46941728 0.61722732 0.3645444  0.         0.\n",
      "  0.3645444  0.         0.3645444 ]\n",
      " [0.         0.7284449  0.         0.28285122 0.         0.47890875\n",
      "  0.28285122 0.         0.28285122]\n",
      " [0.49711994 0.         0.         0.29360705 0.49711994 0.\n",
      "  0.29360705 0.49711994 0.29360705]]\n",
      "Feature names (words): ['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n"
     ]
    }
   ],
   "source": [
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    corpus = ['This is the first document.', 'This document is the second document.', 'And this is the third one.']\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X_tfidf = vectorizer.fit_transform(corpus)\n",
    "    print(\"\\nTF-IDF features:\\n\", X_tfidf.toarray())\n",
    "    print(\"Feature names (words):\", vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616b7d54-1006-46da-a44f-56577147fcc3",
   "metadata": {},
   "source": [
    "# Explanation: \n",
    "      TfidfVectorizer computes the TF-IDF scores for words in a corpus. Words common across many documents receive lower weights, while words unique to specific documents receive higher weights, highlighting their importance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5598d88c-9550-46af-adcd-9d297d1b376c",
   "metadata": {},
   "source": [
    "#  ● Perform exploratory data analysis (EDA) to understand the distribution of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46e3966a-a77b-4ff2-ba9d-a7b94ad94b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "\n",
    "    data = {'text': ['cat food', 'dog toy', 'cat litter', 'dog leash', 'bird seed'],\n",
    "            'category': ['pet_supply', 'pet_supply', 'pet_supply', 'pet_supply', 'pet_supply']}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Example for a categorical column, assuming categories are present\n",
    "    # For text data, you might analyze word frequencies or topic distribution after feature extraction\n",
    "    if 'category' in df.columns:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.countplot(data=df, x='category')\n",
    "        plt.title('Distribution of Categories')\n",
    "        plt.xlabel('Category')\n",
    "        plt.ylabel('Count')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6036b0-a0e2-40be-b9c3-215945abed0b",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "     Word2Vec learns word embeddings by predicting surrounding words (Skip-gram) or predicting a target word from its context (CBOW). The vector_size determines the dimensionality of the word vectors, and window defines the maximum distance between the current and predicted word within a sentence. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc8064e-8dd8-4ba4-8be8-f63c6357ca46",
   "metadata": {},
   "source": [
    "#  3. Model Development and Training\n",
    "# ● Build classification models using algorithms like Logistic Regression, Naive Bayes, Support Vector Machines (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ea2b9e-cb87-42a1-9d97-be207cdd8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building and Training (Logistic Regression Example):\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f457f5a-04f2-4dba-97ba-613b4f271507",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "+ LogisticRegression from sklearn.linear_model is instantiated. You could replace this with GaussianNB for Naive Bayes or SVC for SVM.\n",
    "+ The fit() method trains the model using the vectorized training data (X_train_vec) and their corresponding labels (y_train)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2192bb-b970-45c4-bda1-add4cb42abf7",
   "metadata": {},
   "source": [
    "#  ● Train the models on the preprocessed text data, tuning hyperparameters as necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d6352-cd2b-48ea-b986-0808be243e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning (Example with Logistic Regression):\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10, 100]} # C is a regularization parameter for Logistic Regression\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=3)\n",
    "grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Get the best model and its parameters\n",
    "best_model = grid_search.best_estimator_\n",
    "print(f\"Best hyperparameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44c28e9-71f2-4781-8d67-e566fcf698cb",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "+ GridSearchCV from sklearn.model_selection systematically searches for the best combination of hyperparameters.\n",
    "+ param_grid defines the range of values to test for the C parameter.\n",
    "+ cv=3 specifies 3-fold cross-validation during the grid search.\n",
    "+ best_estimator_ and best_params_ attributes store the best performing model and its corresponding hyperparameters found during the search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3394a8f-8c9d-46a2-aa89-8f2ed6e717bc",
   "metadata": {},
   "source": [
    "#  ● Usecross-validation to ensure robust evaluation of model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b8a27-5375-4b52-85c5-ff77591fa32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Model Evaluation using Cross-Validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation on the training data\n",
    "scores = cross_val_score(best_model, X_train_vec, y_train, cv=5) # 5-fold cross-validation\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation score: {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5568cf5e-0a9d-4ca1-9e85-cddc41877a3b",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "+ cross_val_score from sklearn.Model selection evaluates the model's performance using cross-validation.\n",
    "+ It splits the data into cv (e.g., 5) folds, trains the model on cv-1 folds, and evaluates on the remaining fold, repeating this process cv times.\n",
    "+ The scores array contains the performance metric (e.g., accuracy) for each fold, and the mean provides an overall estimate of model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4f74f6-9bdb-4326-97a9-417202ef4fb5",
   "metadata": {},
   "source": [
    "# CONCLUSION :\n",
    "For Naive Bayes (e.g., GaussianNB, MultinomialNB) and SVM (SVC), the specific hyperparameters and their ranges for tuning will differ. You would also need to ensure your data is appropriately preprocessed for each algorithm (e.g., numerical for Naive Bayes, scaled for SVM)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8215e21-96c7-47df-b606-3f45f38ab590",
   "metadata": {},
   "source": [
    "#  4. Model Evaluation:\n",
    "#  ● Evaluate the models using appropriate metrics.\n",
    "#  ● Comparethe performance of different models and select the best one for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62829326-5617-4470-8d91-aae681f18b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation:\n",
      "\n",
      "--- Logistic Regression ---\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "ROC-AUC: 1.0000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "\n",
      "--- Decision Tree ---\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "ROC-AUC: 1.0000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "\n",
      "--- Random Forest ---\n",
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-Score: 1.0000\n",
      "ROC-AUC: 1.0000\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         3\n",
      "   macro avg       1.00      1.00      1.00         3\n",
      "weighted avg       1.00      1.00      1.00         3\n",
      "\n",
      "\n",
      "--- Model Comparison ---\n",
      "The best model based on Accuracy is: Logistic Regression with Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
    "\n",
    "# 1. Load and prepare your dataset (replace with your actual data)\n",
    "# For demonstration, let's create a dummy dataset\n",
    "data = {\n",
    "    'feature1': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'feature2': [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "    'target': [0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df[['feature1', 'feature2']]\n",
    "y = df['target']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 2. Define and train different classification models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "trained_models = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "\n",
    "# 3. Evaluate the models using appropriate metrics\n",
    "print(\"Model Evaluation:\")\n",
    "results = {}\n",
    "for name, model in trained_models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_prob) if y_prob is not None else 'N/A'\n",
    "\n",
    "    results[name] = {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1,\n",
    "        'ROC-AUC': roc_auc\n",
    "    }\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc_auc:.4f}\" if isinstance(roc_auc, float) else f\"ROC-AUC: {roc_auc}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# 4. Compare the performance and select the best one\n",
    "print(\"\\n--- Model Comparison ---\")\n",
    "best_model_name = None\n",
    "best_accuracy = -1\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    if metrics['Accuracy'] > best_accuracy:\n",
    "        best_accuracy = metrics['Accuracy']\n",
    "        best_model_name = name\n",
    "\n",
    "print(f\"The best model based on Accuracy is: {best_model_name} with Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f503e337-cc08-4341-8a7c-eed48686064e",
   "metadata": {},
   "source": [
    "# Explanation:\n",
    "1. Data Preparation = The code starts by creating a sample dataset and splitting it into training and testing sets. In a real-world scenario, you would load your actual dataset.\n",
    "2. Model Training = Several common classification models (Logistic Regression, Decision Tree, Random Forest) are initialized and trained on the traiN.\n",
    "3. Model Evaluation = Each trained model is evaluated using various classification metrics:\n",
    "  + Accuracy: The proportion of correctly classified instances.\n",
    "  + Precision: The proportion of true positive predictions among all positive predictions.\n",
    "  + Recall (Sensitivity): The proportion of true positive predictions among all actual positive instances.\n",
    "  + F1-Score: The harmonic mean of precision and recall, providing a balance between them.\n",
    "  + ROC-AUC (Receiver Operating Characteristic - Area Under Curve): Measures the ability of the model to distinguish between classes.\n",
    "  + Classification Report: Provides a detailed breakdown of precision, recall, and f1-score for each class\n",
    "4. Model Comparison and Selection = The code then compares the models based on their accuracy and identifies the one with the highest accuracy as the \"best\" model for this specific evaluation. You might choose a different metric (e.g., F1-score, ROC-AUC) depending on your specific problem and priorities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1b78d2-98f2-47d3-b180-2d4ab6e45fd2",
   "metadata": {},
   "source": [
    "# CONCLUSION: \n",
    "This code provides a robust framework for evaluating and comparing different machine learning models for classification tasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311368ba-806e-4c5b-92fb-eb2cfeb56a79",
   "metadata": {},
   "source": [
    "#  Success Criteria:\n",
    "A Python solution for achieving the success criteria outlined in the image would involve implementing a machine learning project for news article classification.\n",
    "# 1. Achieving good performance metrics (accuracy, F1-score, etc.):\n",
    "Use Python libraries like scikit-learn to train a classification model and evaluate its performance using metrics such as accuracy, precision, recall, and F1-score.\n",
    "# Explanation:\n",
    "+ Import necessary modules: from sklearn.model_selection import train_test_split, from sklearn.feature_extraction.text import TfidfVectorizer, from   sklearn.naive_bayes import MultinomialNB, from sklearn.metrics import accuracy_score, f1_score.\n",
    "+ Split your dataset into training and testing sets.\n",
    "+ Vectorize the text data (e.g., using TfidfVectorizer).\n",
    "+ Train a classification model (e.g., MultinomialNB).\n",
    "+ Make predictions on the test set.\n",
    "+ Calculate and print performance metrics like accuracy_score(y_test, y_pred) and f1_score(y_test, y_pred, average='weighted').\n",
    "# 2. Successfully classifying new, unseen news articles into correct categories:\n",
    "Deploy the trained model to classify new, previously unseen news articles.\n",
    "# Explanation:\n",
    "+ Load the trained model and the vectorizer.\n",
    "+ Preprocess the new news article text in the same way as the training data (vectorization).\n",
    "+ Use the predict() method of the trained model to assign the article to a category (e.g., sports, politics, technology).\n",
    "# 3. Deriving insights regarding important features or keywords:\n",
    " Analyze the trained model to extract feature importance or identify key terms driving the classification.\n",
    "+ For models like Naive Bayes or Logistic Regression, you can inspect the learned coefficients or feature weights to understand which words or features contribute most to each category.\n",
    "+ Techniques like SHAP (SHapley Additive exPlanations) or LIME (Local Interpretable Model-agnostic Explanations) can be used for more complex models to explain individual predictions and identify important features.\n",
    "# 4. Clearly documenting and presenting the process and methodology:\n",
    "Use tools like Jupyter Notebooks, Markdown, or Sphinx to document the code, methodology, data sources, model choices, and evaluation results.\n",
    "# Explanation:\n",
    "+ Jupyter Notebooks: Provide a runnable and interactive environment to combine code, explanations, and visualizations.\n",
    "+ Markdown: Create clear and concise README files or project reports explaining the steps taken, data preparation, model training, and results.\n",
    "+ Comments in Code: Add detailed comments within your Python scripts to explain different parts of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420cb32-5693-4348-86b2-9c00ef2567fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
